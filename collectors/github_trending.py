#!/usr/bin/env python3
"""GitHub Trending æ”¶é›†å™¨ - çƒ­é—¨å¼€æºé¡¹ç›®"""

import requests
from typing import List, Dict, Any
from datetime import datetime


class GitHubTrendingCollector:
    """GitHub Trending é¡¹ç›®æ”¶é›†å™¨"""
    
    def __init__(self):
        self.base_url = "https://github.com/trending"
        self.languages = ["", "Python", "JavaScript", "TypeScript"]  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºå…¨éƒ¨
    
    def fetch(self, limit: int = 20) -> List[Dict[str, Any]]:
        """
        è·å– GitHub Trending é¡¹ç›®
        
        Args:
            limit: è·å–æ•°é‡
            
        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        items = []
        
        # è·å–é»˜è®¤è¯­è¨€åˆ—è¡¨çš„ Trending
        try:
            trending_items = self._fetch_trending(limit)
            items.extend(trending_items)
        except Exception as e:
            print(f"GitHub Trending error: {e}")
        
        print(f"Got {len(items)} GitHub Trending items")
        return items
    
    def _fetch_trending(self, limit: int) -> List[Dict[str, Any]]:
        """æŠ“å– GitHub Trending é¡µé¢"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(self.base_url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            print(f"  GitHub Trending: HTTP {response.status_code}")
            return []
        
        items = []
        html = response.text
        
        # ç®€å•è§£æ HTML
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, 'html.parser')
        
        articles = soup.find_all('article', class_='Box-row')
        
        for article in articles[:limit]:
            try:
                # è·å–é¡¹ç›®æ ‡é¢˜
                title_elem = article.find('h2', class_='h3').find('a')
                if not title_elem:
                    continue
                
                full_name = title_elem.get('href', '').strip('/')
                name_parts = full_name.split('/')
                
                if len(name_parts) != 2:
                    continue
                
                author, name = name_parts
                
                # è·å–æè¿°
                desc_elem = article.find('p', class_='col-9')
                description = desc_elem.get_text(strip=True)[:500] if desc_elem else ''
                
                # è·å– star æ•°
                star_elem = article.find('a', href=lambda x: x and '/stargazers' in x)
                stars_text = star_elem.get_text(strip=True) if star_elem else '0'
                stars = self._parse_number(stars_text)
                
                # è·å– fork æ•°
                fork_elem = article.find('a', href=lambda x: x and '/forks' in x)
                forks_text = fork_elem.get_text(strip=True) if fork_elem else '0'
                forks = self._parse_number(forks_text)
                
                # è·å–è¯­è¨€
                lang_elem = article.find('span', itemprop='programmingLanguage')
                language = lang_elem.get_text(strip=True) if lang_elem else ''
                
                items.append({
                    'id': f"github_{full_name.replace('/', '_')}",
                    'title': f"{name} - {description[:100] if description else 'GitHub Trending Project'}",
                    'source': 'github_trending',
                    'url': f"https://github.com/{full_name}",
                    'score': stars,  # ç”¨ star æ•°ä½œä¸ºè¯„åˆ†å‚è€ƒ
                    'description': f"**{name}** by @{author}\n\n{description}\n\nâ­ {stars} | ğŸ´ {forks} | ğŸ’» {language or 'Unknown'}",
                    'author': author,
                    'created_at': datetime.now().isoformat(),
                    'metadata': {
                        'full_name': full_name,
                        'stars': stars,
                        'forks': forks,
                        'language': language
                    }
                })
                
            except Exception as e:
                print(f"  Parse error: {e}")
                continue
        
        return items
    
    def _parse_number(self, text: str) -> int:
        """è§£ææ•°å­—ï¼ˆå¤„ç† k, M ç­‰å•ä½ï¼‰"""
        text = text.replace(',', '').strip()
        
        if not text:
            return 0
        
        try:
            if 'k' in text.lower():
                return int(float(text.lower().replace('k', '')) * 1000)
            elif 'm' in text.lower():
                return int(float(text.lower().replace('m', '')) * 1000000)
            else:
                return int(text)
        except:
            return 0


# æµ‹è¯•
if __name__ == '__main__':
    collector = GitHubTrendingCollector()
    items = collector.fetch(limit=5)
    
    print(f"\nGot {len(items)} items\n")
    for i, item in enumerate(items[:3], 1):
        print(f"{i}. {item['title'][:60]}...")
        print(f"   URL: {item['url']}")
        print(f"   Stars: {item['metadata']['stars']:,}")
        print()
