#!/usr/bin/env python3
"""
è°ƒç ” Agent - å‘ç°äº§å“æœºä¼š

ç”¨æ³•:
    python3 main.py              # æ‰‹åŠ¨è¿è¡Œ
    python3 main.py --test       # æµ‹è¯•æ¨¡å¼
    python3 main.py --debug      # è°ƒè¯•æ¨¡å¼

é…ç½®:
    å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å†™ API Key
"""

import os
import sys
import json
import asyncio
import argparse
from datetime import datetime
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from mvp_generator import MVPGenerator
from config import DEBUG, DATA_DIR, LOG_DIR, BAILIAN_API_KEY, FEISHU_USER_ID, validate_config, GITHUB_TOKEN, GITHUB_REPO
from collectors import HNCollector, PHCollector, ChineseMediaCollector, GitHubTrendingCollector
from collectors.indiehackers import IndieHackersCollector
from collectors.reddit import RedditCollector
from analyzers import BailianAnalyzer
from models import Opportunity


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    import logging as loglib
    
    log_file = os.path.join(LOG_DIR, f"research_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ç®€å•çš„æ—¥å¿—é…ç½®
    loglib.basicConfig(
        level=loglib.DEBUG if DEBUG else loglib.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            loglib.FileHandler(log_file),
            loglib.StreamHandler()
        ]
    )
    return loglib.getLogger(__name__)


def collect_data(hn_limit: int = 10, ph_limit: int = 5, twitter_limit: int = 20, 
                 media_hours: int = 48, crunchbase_limit: int = 10) -> List[dict]:
    """æ”¶é›†æ•°æ®"""
    import logging
    logger = logging.getLogger(__name__)
    
    items = []
    
    # Hacker News
    logger.info(f"Fetching HN (limit={hn_limit})...")
    hn_items = HNCollector.fetch(limit=hn_limit)
    logger.info(f"Got {len(hn_items)} HN items")
    items.extend(hn_items)
    
    # Product Hunt
    logger.info(f"Fetching PH (limit={ph_limit})...")
    ph_items = PHCollector.fetch(limit=ph_limit)
    logger.info(f"Got {len(ph_items)} PH items")
    items.extend(ph_items)
    
    
    # Chinese Media (36Kr, Huxiu, etc.)
    logger.info(f"Fetching Chinese Media (hours={media_hours})...")
    media_items = ChineseMediaCollector.fetch(hours=media_hours, limit=20)
    logger.info(f"Got {len(media_items)} Chinese media items")
    items.extend(media_items)
    
    
    # IndieHackers (solo founder stories)
    logger.info(f"Fetching IndieHackers (limit=15)...")
    ih_collector = IndieHackersCollector()
    ih_items = ih_collector.fetch(limit=15)
    logger.info(f"Got {len(ih_items)} IndieHackers items")
    items.extend(ih_items)
    
    return items


def analyze_items(items: List[dict], min_score: int = 60) -> List[Opportunity]:
    """åˆ†æé¡¹ç›®"""
    return asyncio.run(analyze_items_async(items, min_score=min_score))


async def analyze_items_async(items: List[dict], min_score: int = 60) -> List[Opportunity]:
    """å¼‚æ­¥åˆ†æé¡¹ç›®"""
    import logging
    logger = logging.getLogger(__name__)
    
    if not BAILIAN_API_KEY:
        logger.error("BAILIAN_API_KEY not configured")
        return []
    
    analyzer = BailianAnalyzer()
    
    logger.info(f"Analyzing {len(items)} items (min_score={min_score})...")
    opportunities = await analyzer.batch_analyze_async(items, min_score=min_score)
    logger.info(f"Found {len(opportunities)} opportunities")
    
    return opportunities


def save_results(opportunities: List[Opportunity]):
    """ä¿å­˜ç»“æœ"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜ JSON
    json_file = os.path.join(DATA_DIR, f"opportunities_{timestamp}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        try:
            json.dump([opp.to_dict() for opp in opportunities], f, ensure_ascii=False, indent=2)
        except (TypeError, ValueError) as e:
            print(f"JSON serialization error: {e}")
            # å°è¯•ç®€åŒ–æ•°æ®
            simple_data = []
            for opp in opportunities:
                try:
                    simple_data.append({
                        'id': opp.id,
                        'title': opp.title,
                        'score': opp.score
                    })
                except Exception:
                    continue
            json.dump(simple_data, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æœ€æ–°ç»“æœ
    latest_file = os.path.join(DATA_DIR, "latest.json")
    try:
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump([opp.to_dict() for opp in opportunities], f, ensure_ascii=False, indent=2)
    except (IOError, OSError) as e:
        print(f"Error saving latest.json: {e}")
    
    print(f"Saved to {json_file}")


def send_to_feishu(opportunities: List[Opportunity]):
    """å‘é€åˆ°é£ä¹¦ï¼ˆé€šè¿‡ OpenClaw CLIï¼‰"""
    if not FEISHU_USER_ID:
        print("FEISHU_USER_ID not configured, skipping Feishu notification")
        return
    
    try:
        import subprocess
        
        # å‘é€ Top 10
        for opp in opportunities[:10]:
            msg = opp.to_message()
            cmd = [
                "openclaw", "message", "send",
                "--channel", "feishu",
                "--target", f"user:{FEISHU_USER_ID}",
                "--message", msg,
                "--silent"
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                print(f"âœ… Sent to Feishu: {opp.title[:50]}...")
            else:
                print(f"âš ï¸  Send failed: {result.stderr[:100]}")
        
        print(f"âœ… Sent Top {min(10, len(opportunities))} opportunities to Feishu")
        
    except Exception as e:
        print(f"Error sending to Feishu: {e}")


def create_github_issues(opportunities: List[Opportunity]):
    """è‡ªåŠ¨åˆ›å»º GitHub Issue"""
    if not GITHUB_TOKEN:
        print("âš ï¸  GITHUB_TOKEN not configured, skipping GitHub issues")
        print("   Configure: echo 'ghp_xxx' > ~/.github_token")
        return
    
    import requests
    
    url = f"https://api.github.com/repos/{GITHUB_REPO}/issues"
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Accept": "application/vnd.github.v3+json"
    }
    
    created = 0
    for opp in opportunities[:3]:  # åªåˆ›å»º Top 3
        try:
            data = {
                "title": f"ğŸš€ {opp.title[:50]} - {opp.score}åˆ†æœºä¼š",
                "body": f"""## ğŸ“Š æœºä¼šè¯„ä¼°

- **è¯„åˆ†**: {opp.score}/100
- **æ¥æº**: {opp.source.upper()}
- **å‘ç°æ—¥æœŸ**: {opp.created_at.strftime('%Y-%m-%d')}

## ğŸ“– é¡¹ç›®ä»‹ç»

{opp.description if opp.description else opp.summary}

## ğŸ‘¤ ä¸€äººå…¬å¸å¯è¡Œæ€§

{opp.solo_feasibility if opp.solo_feasibility else 'å¾…åˆ†æ'}

## ğŸ’° å•†ä¸šæ¨¡å¼

- å¯åŠ¨æˆæœ¬ï¼š{opp.startup_cost or 'å¾…åˆ†æ'}
- å¤šä¹…è§é’±ï¼š{opp.time_to_revenue or 'å¾…åˆ†æ'}
- æœˆæ”¶å…¥æ½œåŠ›ï¼š{opp.monthly_potential or 'å¾…åˆ†æ'}
- è‡ªåŠ¨åŒ–ç‡ï¼š{opp.automation_rate or 'å¾…åˆ†æ'}

## ğŸš€ ç¬¬ä¸€æ­¥

{opp.action_plan if opp.action_plan else 'å¾…åˆ†æ'}

## ğŸ“„ è¯¦æƒ…

https://github.com/{GITHUB_REPO}/blob/main/opportunities/{opp.created_at.strftime('%Y-%m-%d')}_{opp.id}.md

---
*Auto-created by Research Agent*""",
                "labels": ["opportunity", "researching", "ai"]
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 201:
                issue_url = response.json().get('html_url', '')
                print(f"âœ… Created Issue: {issue_url}")
                created += 1
            else:
                print(f"âš ï¸  Failed: {response.status_code} - {response.text[:100]}")
                
        except Exception as e:
            print(f"âš ï¸  Error: {e}")
    
    print(f"âœ… Created {created}/3 GitHub issues")




def generate_mvps(opportunities: List[Opportunity]):
    """ä¸º Top æœºä¼šç”Ÿæˆ MVP"""
    print("\nğŸš€ Generating MVPs...")
    
    generator = MVPGenerator()
    generated = 0
    
    for opp in opportunities[:2]:  # åªä¸º Top 2 ç”Ÿæˆ MVP
        try:
            opp_dict = {
                'title': opp.title,
                'summary': opp.summary,
                'description': opp.description or opp.summary,
                'score': opp.score,
                'revenue_model': opp.revenue_model or 'Subscription',
                'startup_cost': opp.startup_cost or '$1-5k',
                'time_to_revenue': opp.time_to_revenue or '30 days',
                'monthly_potential': opp.monthly_potential or '$10-50k',
                'automation_rate': opp.automation_rate or '90%+',
                'agent_roles': opp.agent_roles or ['Development Agent']
            }
            
            project_dir = generator.generate(opp_dict)
            if project_dir:
                generated += 1
                print(f"âœ… Generated: {project_dir}")
        except Exception as e:
            print(f"âš ï¸  Failed to generate MVP for {opp.title}: {e}")
    
    print(f"\nâœ… Generated {generated}/{len(opportunities[:2])} MVPs")

def print_results(opportunities: List[Opportunity]):
    """æ‰“å°ç»“æœ"""
    print("\n" + "="*80)
    print(f"å‘ç° {len(opportunities)} ä¸ªäº§å“æœºä¼š")
    print("="*80 + "\n")
    
    for i, opp in enumerate(opportunities[:5], 1):  # åªæ˜¾ç¤º top 5
        print(f"#{i} [{opp.source.upper()}] è¯„åˆ†ï¼š{opp.score}/100")
        print(f"   æ ‡é¢˜ï¼š{opp.title}")
        print(f"   é“¾æ¥ï¼š{opp.url}")
        print()
        print(f"   ğŸ“– é¡¹ç›®ä»‹ç»")
        print(f"   {opp.description[:200] if opp.description else opp.summary[:200]}...")
        print()
        print(f"   ğŸ‘¤ ä¸€äººå…¬å¸å¯è¡Œæ€§")
        print(f"   {opp.solo_feasibility[:150] if opp.solo_feasibility else 'å¾…åˆ†æ'}...")
        print()
        print(f"   ğŸ¤– Agent è§’è‰²ï¼š{', '.join(opp.agent_roles) if opp.agent_roles else 'å¾…åˆ†æ'}")
        print(f"   ğŸ’° å¯åŠ¨æˆæœ¬ï¼š{opp.startup_cost or 'å¾…åˆ†æ'}")
        print(f"   â±ï¸ å¤šä¹…è§é’±ï¼š{opp.time_to_revenue or 'å¾…åˆ†æ'}")
        print(f"   ğŸ“ˆ æ”¶å…¥æ¨¡å¼ï¼š{opp.revenue_model or 'å¾…åˆ†æ'}")
        print(f"   ğŸ¯ æœˆæ”¶å…¥æ½œåŠ›ï¼š{opp.monthly_potential or 'å¾…åˆ†æ'}")
        print(f"   âš™ï¸ è‡ªåŠ¨åŒ–ç‡ï¼š{opp.automation_rate or 'å¾…åˆ†æ'}")
        print(f"   ğŸ“¢ è·å®¢æ¸ é“ï¼š{opp.customer_acquisition or 'å¾…åˆ†æ'}")
        print()
        print(f"   âš ï¸ é£é™©")
        print(f"   {opp.risks[:150] if opp.risks else 'å¾…åˆ†æ'}...")
        print()
        print(f"   ğŸš€ ç¬¬ä¸€æ­¥")
        print(f"   {opp.action_plan[:100] if opp.action_plan else 'å¾…åˆ†æ'}...")
        print()
        print(f"   ğŸ”— ç›¸å…³é“¾æ¥")
        print(f"   - åŸå§‹é“¾æ¥ï¼š{opp.source_url}")
        for link in opp.research_links[1:3]:  # æ˜¾ç¤ºç ”ç©¶é“¾æ¥
            print(f"   - {link}")
        print()
        print("-"*80 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    # éªŒè¯é…ç½®
    try:
        validate_config()
    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯ï¼š{e}")
        print("è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="è°ƒç ” Agent - å‘ç°äº§å“æœºä¼š")
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--hn-limit', type=int, default=30, help='HN è·å–æ•°é‡')
    parser.add_argument('--ph-limit', type=int, default=20, help='PH è·å–æ•°é‡')
    parser.add_argument('--min-score', type=int, default=60, help='æœ€ä½åˆ†æ•°')
    parser.add_argument('--indie-mode', action='store_true', help='ä¸€äººå…¬å¸æ¨¡å¼ï¼šä¸“æ³¨ Indie Hacker/å¾® SaaS/è‡ªåŠ¨åŒ–æœºä¼š')
    
    args = parser.parse_args()
    
    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    if args.debug:
        os.environ['DEBUG'] = 'true'
    
    global DEBUG
    DEBUG = args.debug or DEBUG
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    logger.info("Starting research agent...")
    
    # æ£€æŸ¥ API Key
    if not BAILIAN_API_KEY:
        logger.error("BAILIAN_API_KEY not configured. Please set it in .env file.")
        print("é”™è¯¯ï¼šè¯·é…ç½® BAILIAN_API_KEY")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. å¡«å†™ä½ çš„é˜¿é‡Œç™¾ç‚¼ API Key")
        sys.exit(1)
    
    # æµ‹è¯•æ¨¡å¼
    if args.test:
        logger.info("Test mode: fetching sample data...")
        items = collect_data(hn_limit=5, ph_limit=3)
        print(f"Collected {len(items)} items")
        for item in items[:3]:
            print(f"  - {item['title']}")
        return
    
    # æ­£å¸¸è¿è¡Œ
    items = collect_data(hn_limit=args.hn_limit, ph_limit=args.ph_limit)
    opportunities = asyncio.run(analyze_items_async(items, min_score=args.min_score))
    
    if opportunities:
        save_results(opportunities)
        print_results(opportunities)
        send_to_feishu(opportunities)
        create_github_issues(opportunities)
        generate_mvps(opportunities)
    else:
        print("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æœºä¼š")


if __name__ == "__main__":
    main()
