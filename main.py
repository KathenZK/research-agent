#!/usr/bin/env python3
"""
è°ƒç ” Agent - å‘ç°äº§å“æœºä¼š

ç”¨æ³•:
    python3 main.py              # æ‰‹åŠ¨è¿è¡Œ
    python3 main.py --test       # æµ‹è¯•æ¨¡å¼
    python3 main.py --debug      # è°ƒè¯•æ¨¡å¼

é…ç½®:
    å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å†™ API Key
"""

import os
import sys
import json
import argparse
from datetime import datetime
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import DEBUG, DATA_DIR, LOG_DIR, BAILIAN_API_KEY, FEISHU_USER_ID, validate_config
from collectors import HNCollector, PHCollector
from analyzers import BailianAnalyzer
from models import Opportunity


def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    import logging as loglib
    
    log_file = os.path.join(LOG_DIR, f"research_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ç®€å•çš„æ—¥å¿—é…ç½®
    loglib.basicConfig(
        level=loglib.DEBUG if DEBUG else loglib.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            loglib.FileHandler(log_file),
            loglib.StreamHandler()
        ]
    )
    return loglib.getLogger(__name__)


def collect_data(hn_limit: int = 30, ph_limit: int = 20) -> List[dict]:
    """æ”¶é›†æ•°æ®"""
    import logging
    logger = logging.getLogger(__name__)
    
    items = []
    
    # Hacker News
    logger.info(f"Fetching HN (limit={hn_limit})...")
    hn_items = HNCollector.fetch(limit=hn_limit)
    logger.info(f"Got {len(hn_items)} HN items")
    items.extend(hn_items)
    
    # Product Hunt
    logger.info(f"Fetching PH (limit={ph_limit})...")
    ph_items = PHCollector.fetch(limit=ph_limit)
    logger.info(f"Got {len(ph_items)} PH items")
    items.extend(ph_items)
    
    return items


def analyze_items(items: List[dict], min_score: int = 60) -> List[Opportunity]:
    """åˆ†æé¡¹ç›®"""
    import logging
    logger = logging.getLogger(__name__)
    
    if not BAILIAN_API_KEY:
        logger.error("BAILIAN_API_KEY not configured")
        return []
    
    analyzer = BailianAnalyzer()
    
    logger.info(f"Analyzing {len(items)} items (min_score={min_score})...")
    opportunities = analyzer.batch_analyze(items, min_score=min_score)
    logger.info(f"Found {len(opportunities)} opportunities")
    
    return opportunities


def save_results(opportunities: List[Opportunity]):
    """ä¿å­˜ç»“æœ"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # ä¿å­˜ JSON
    json_file = os.path.join(DATA_DIR, f"opportunities_{timestamp}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        try:
            json.dump([opp.to_dict() for opp in opportunities], f, ensure_ascii=False, indent=2)
        except (TypeError, ValueError) as e:
            print(f"JSON serialization error: {e}")
            # å°è¯•ç®€åŒ–æ•°æ®
            simple_data = []
            for opp in opportunities:
                try:
                    simple_data.append({
                        'id': opp.id,
                        'title': opp.title,
                        'score': opp.score
                    })
                except Exception:
                    continue
            json.dump(simple_data, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æœ€æ–°ç»“æœ
    latest_file = os.path.join(DATA_DIR, "latest.json")
    try:
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump([opp.to_dict() for opp in opportunities], f, ensure_ascii=False, indent=2)
    except (IOError, OSError) as e:
        print(f"Error saving latest.json: {e}")
    
    print(f"Saved to {json_file}")


def send_to_feishu(opportunities: List[Opportunity]):
    """å‘é€åˆ°é£ä¹¦"""
    if not FEISHU_USER_ID:
        print("FEISHU_USER_ID not configured, skipping Feishu notification")
        return
    
    try:
        # ä½¿ç”¨ OpenClaw message å·¥å…·å‘é€
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨ OpenClaw API
        print(f"Would send {len(opportunities)} opportunities to Feishu user {FEISHU_USER_ID}")
        
        # TODO: é›†æˆ OpenClaw message API
        # from openclaw import message
        # for opp in opportunities[:3]:  # åªå‘é€ top 3
        #     message.send(
        #         channel="feishu",
        #         target=FEISHU_USER_ID,
        #         message=opp.to_message()
        #     )
        
    except Exception as e:
        print(f"Error sending to Feishu: {e}")


def print_results(opportunities: List[Opportunity]):
    """æ‰“å°ç»“æœ"""
    print("\n" + "="*80)
    print(f"å‘ç° {len(opportunities)} ä¸ªäº§å“æœºä¼š")
    print("="*80 + "\n")
    
    for i, opp in enumerate(opportunities[:5], 1):  # åªæ˜¾ç¤º top 5
        print(f"#{i} [{opp.source.upper()}] è¯„åˆ†ï¼š{opp.score}/100")
        print(f"   æ ‡é¢˜ï¼š{opp.title}")
        print(f"   é“¾æ¥ï¼š{opp.url}")
        print()
        print(f"   ğŸ“– é¡¹ç›®ä»‹ç»")
        print(f"   {opp.description[:200]}...")
        print()
        print(f"   ğŸ’° ç›ˆåˆ©æ¨¡å¼")
        print(f"   {opp.business_model[:150] if opp.business_model else 'å¾…åˆ†æ'}...")
        print()
        print(f"   ğŸ† ç«äº‰å¯¹æ‰‹")
        print(f"   {opp.competitors[:150] if opp.competitors else 'å¾…åˆ†æ'}...")
        print()
        print(f"   ğŸ’¡ å»ºè®®æ–¹å‘")
        print(f"   {opp.suggestion[:150]}...")
        print()
        print(f"   ğŸ”— ç›¸å…³é“¾æ¥")
        print(f"   - åŸå§‹é“¾æ¥ï¼š{opp.source_url}")
        for link in opp.research_links[1:3]:  # æ˜¾ç¤ºç ”ç©¶é“¾æ¥
            print(f"   - {link}")
        print()
        print("-"*80 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    # éªŒè¯é…ç½®
    try:
        validate_config()
    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯ï¼š{e}")
        print("è¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
        sys.exit(1)
    
    parser = argparse.ArgumentParser(description="è°ƒç ” Agent - å‘ç°äº§å“æœºä¼š")
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--hn-limit', type=int, default=30, help='HN è·å–æ•°é‡')
    parser.add_argument('--ph-limit', type=int, default=20, help='PH è·å–æ•°é‡')
    parser.add_argument('--min-score', type=int, default=60, help='æœ€ä½åˆ†æ•°')
    
    args = parser.parse_args()
    
    # è®¾ç½®è°ƒè¯•æ¨¡å¼
    if args.debug:
        os.environ['DEBUG'] = 'true'
    
    global DEBUG
    DEBUG = args.debug or DEBUG
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    logger.info("Starting research agent...")
    
    # æ£€æŸ¥ API Key
    if not BAILIAN_API_KEY:
        logger.error("BAILIAN_API_KEY not configured. Please set it in .env file.")
        print("é”™è¯¯ï¼šè¯·é…ç½® BAILIAN_API_KEY")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. å¡«å†™ä½ çš„é˜¿é‡Œç™¾ç‚¼ API Key")
        sys.exit(1)
    
    # æµ‹è¯•æ¨¡å¼
    if args.test:
        logger.info("Test mode: fetching sample data...")
        items = collect_data(hn_limit=5, ph_limit=3)
        print(f"Collected {len(items)} items")
        for item in items[:3]:
            print(f"  - {item['title']}")
        return
    
    # æ­£å¸¸è¿è¡Œ
    items = collect_data(hn_limit=args.hn_limit, ph_limit=args.ph_limit)
    opportunities = analyze_items(items, min_score=args.min_score)
    
    if opportunities:
        save_results(opportunities)
        print_results(opportunities)
        send_to_feishu(opportunities)
    else:
        print("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„æœºä¼š")


if __name__ == "__main__":
    main()
